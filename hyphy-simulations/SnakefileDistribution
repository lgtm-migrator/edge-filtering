## import all functions from python ## 
from python.temp import *
from python.edge_report import edge_report, consolidate_edge_reports
from python.sum_stats_table import sum_stats_table
from python.graph import sum_stats_graph
import multiprocessing
import itertools
import os
import datetime as dt
import numpy as np
from snakemake.utils import read_job_properties
import random

shell.prefix("source /opt/edge-filtering/edge/bin/activate;module load aocc/1.2.1;export PATH=/usr/local/bin:$PATH; ")

pid = str(config["seed"])

# use the time to organize runs
time = str(dt.datetime.now()).split(' ')[0]

# size of the networks to create #
network_sizes = list([config["chain_size"]])

# Beta distribution according to LANL
# (2.6711811991141117, 0.9048171772138711, -0.00148892720428367, 0.016488927204283674)

# Evolution parameters #
# within host Ev #
#TIP_LENGTH = list(np.arange(0.01, 0.15, 0.01))

# between host Ev #
#INTERNAL_LENGTH = list(np.arange(0.01, 0.15, 0.01))
FORMAT = "hyphy"

# number of simulations #
sims = 1
number_of_sims = [[i]*sims for i in network_sizes]
flatten = [j for i in number_of_sims for j in i]

INDEX = []
for i in number_of_sims:
    for pos, item in enumerate(i):
        INDEX.append(str(pos))

PAIRS = list(zip(flatten,INDEX))
temp = [str(p[0])+'_'+p[1] for p in PAIRS]
temp = ['{}'.format(*x) for x in temp]

def edge_create(pair):
  tokens = pair[0].split('_')
  node = tokens[0]
  output_fn = pair[1]
  edge_creator_dist(node, FORMAT, output_fn)

rule all: 
    params: 
        runtime="5:00:00"
    input:        
        pid + "/data/summary_statistics_FDR_graph.png",
        pid + "/data/summary_statistics_TDR_graph.png",
        pid + "/data/summary_statistics_funnel_graph.png",
        pid + "/data/summary_statistics_sqrt_funnel_graph.png",
        pid + "/data/all_edge_report.json"
        #"data/summary_statistics_table.csv"


## this rule that will use the python script to make and write matrices to .ibf files ## 
rule matrix_for_BF:
    params: 
        temp=temp,
        runtime="5:00:00"
    output: 
        expand(os.path.join(os.getcwd(), pid + "/data/matrix/{temp}_nodes.ibf"), temp=temp)
    run:
        cpu_count = snakemake.available_cpu_count()
        with multiprocessing.Pool(cpu_count) as p:
          p.map(edge_create, zip(params.temp,output))

## this rule will take the matrices and input them into the sim_seq.bf to make fasta files ##
rule seq_gen:
    params:
        runtime="5:00:00"
    input:
        os.path.join(os.getcwd(), pid + "/data/matrix/{temp}_nodes.ibf")
    output:
        pid + "/data/sim_seq/{temp}_sim.fasta"
    group:"hivtrace"
    shell:  
        "HYPHYMP simulate/SimulateSequence.bf {input} > {output}"


## this rule will take the generated fasta files and input them into HIVtrace 
rule hiv_trace_with_edge_filtering:
    params:
        runtime="5:00:00"
    input:
        rules.seq_gen.output
    output:
        pid + "/data/hivtrace/{temp}_nodes.results.json", pid + "/data/hivtrace/{temp}_nodes.results.log"
    group:"hivtrace"
    shell:
        "hivtrace --do-not-store-intermediate -i {input} -a resolve -f remove -r HXB2_prrt -t .015 -m 500 -g .05 -o {output[0]} --log {output[1]}"

## this rule will take the generated fasta files and input them into HIVtrace 
rule hiv_trace_without_edge_filtering:
    params:
        runtime="5:00:00"
    input:
        rules.seq_gen.output
    output:
        pid + "/data/hivtrace/{temp}_nodes.nofilter.results.json", pid + "/data/hivtrace/{temp}_nodes.nofilter.results.log"
    group:"hivtrace"
    shell:
        "hivtrace --do-not-store-intermediate -i {input} -a resolve -r HXB2_prrt -t .015 -m 500 -g .05 -o {output[0]} --log {output[1]} "

## this rule will take the generated fasta files and input them into HIVtrace 
rule hiv_trace_with_cycle_filtering:
    params:
        runtime="5:00:00"
    input:
        rules.seq_gen.output
    output:
        pid + "/data/hivtrace/{temp}_nodes.cycle.results.json", pid + "/data/hivtrace/{temp}_nodes.cycle_report.json", pid + "/data/hivtrace/{temp}_nodes.cycle.results.log"
    group:"hivtrace"
    shell:
        "hivtrace --do-not-store-intermediate -i {input} -a resolve -f remove -r HXB2_prrt -t .015 -m 500 -g .05 -o {output[0]} --filter-cycles --cycle-report-fn {output[1]} --log {output[2]}"


rule generate_edge_report:
    params:
        runtime="5:00:00"
    input:
        with_edge_filtering=rules.hiv_trace_with_edge_filtering.output,
        with_out_edge_filtering=rules.hiv_trace_without_edge_filtering.output,
        with_cycle_filtering=rules.hiv_trace_with_cycle_filtering.output
    output:
        pid + "/data/hivtrace/{temp}_edge_report.json"
    group:"report"
    run:
        transmission_chains=[matrix_maker_dist(config['chain_size']) for n in input.with_edge_filtering]
        pairs = zip(input.with_edge_filtering, input.with_out_edge_filtering, [input.with_cycle_filtering[0]], [input.with_cycle_filtering[1]], transmission_chains, output)
        for p in pairs:
            edge_report(*p)


## this rule consumes all the edge reports and creates a table with all the info ##
rule generate_all_edge_report:
    params:
        runtime="5:00:00"
    input:
        expand(pid + "/data/hivtrace/{temp}_edge_report.json", temp=temp)
    output:
        pid + "/data/all_edge_report.json"
    group:"report"
    run:
        consolidate_edge_reports(temp, input, output[0])

rule summary_stats_table:
    params:
        runtime="5:00:00"
    input:
        expand(pid + "/data/hivtrace/{temp}_edge_report.json", temp=temp)
    output:
        pid + "/data/summary_statistics_table.csv"
    group:"report"
    run:
        sum_stats_table(input, output, sims)

## this rule consumes all the edge reports and creates FDR, TDR, and funnel graphs with all the info ##
rule summary_stats_graph:
    params:
        runtime="5:00:00"
    input:
        rules.summary_stats_table.output
    output:
        pid + "/data/summary_statistics_FDR_graph.png",
        pid + "/data/summary_statistics_TDR_graph.png",
        pid + "/data/summary_statistics_funnel_graph.png",
        pid + "/data/summary_statistics_sqrt_funnel_graph.png"
    group:"report"
    run:
        sum_stats_graph(input, output[0], output[1], output[2], output[3], sims, 0, 0)

